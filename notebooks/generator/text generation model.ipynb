{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3421ceea-03bd-47bb-8588-9ed8a25f7fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50916a0e-e296-4dcb-8a00-05f6042f4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb46f31-9d8c-4d74-97f0-0b68ea6f888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.get_default_device()\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d139ca32-6803-429a-ae10-19f99953dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "596ade78-b128-4bbd-a767-d7195f3f7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the model input\n",
    "prompt = \"\"\"\n",
    "SYSTEM / INSTRUCTIONS FOR THE MODEL:\n",
    "You are an expert resume writer and career coach specialized in rewriting candidate experiences to match job descriptions.  \n",
    "You will be given an array of items. Each item contains:\n",
    "  1) \"jd_snippet\": a short text span taken from a job description (responsibility, role, or technology).\n",
    "  2) \"candidate_experiences\": a (possibly empty) list of the candidate's past experience items relevant to that jd_snippet. Each candidate experience is a short paragraph describing what they did, technologies used, and any achievements (may or may not include quantitative impact).\n",
    "\n",
    "Your task: For each item, produce a set of resume-ready experience lines that can be directly added to the candidate's CV. Use the candidate_experiences when available to create factual, tailored bullets. If candidate_experiences is empty, generate plausible, conservative, and honest-sounding suggested bullets aligned to the jd_snippet (mark them as suggestions). When a quantitative impact is missing in a source experience, the model should **propose** a realistic, conservative numeric impact and mark that number as suggested.\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Output must be exactly one JSON object following this schema. Do not output anything else (no commentary, no markdown, no extra keys).\n",
    "\n",
    "Root object schema:\n",
    "{\n",
    "  \"generated_at\": \"<ISO8601 timestamp>\",\n",
    "  \"job_customizations\": [\n",
    "    {\n",
    "      \"jd_snippet\": \"<original job description snippet>\",\n",
    "      \"matches\": [\n",
    "        {\n",
    "          \"source_experience\": \"<original candidate experience text or empty string if none>\",\n",
    "          \"resume_bullet\": \"<single resume bullet — 1-2 sentences, action-first, past tense for prior roles, present for current role>\",\n",
    "          \"skills\": [\"comma-separated skill tags\"],\n",
    "          \"impact\": {\n",
    "            \"value\": \"<numeric value or string with units, e.g. '25%' or 'reduced latency by 300ms' or null>\",\n",
    "            \"is_suggested\": <true|false>,\n",
    "            \"explain\": \"<1-2 sentence note about how the impact was obtained or why it was suggested>\"\n",
    "          },\n",
    "          \"confidence\": \"<HIGH | MEDIUM | LOW>\",\n",
    "          \"rationale\": \"<brief 1-sentence mapping explaining which parts of the jd_snippet and source_experience were used to create this bullet>\"\n",
    "        }\n",
    "        /* up to 3 matches per jd_snippet */\n",
    "      ],\n",
    "      \"notes\": \"<optional short note if any special assumptions were made; empty string if none>\"\n",
    "    }\n",
    "    /* one object per jd_snippet in input */\n",
    "  ],\n",
    "  \"warnings\": [\"...\"]   /* array of strings; e.g. if many suggestions used, warn reviewer */\n",
    "}\n",
    "\n",
    "OUTPUT RULES (strict):\n",
    "1. Provide up to 3 resume bullets (matches) per jd_snippet. Prefer 1–2 strong bullets.\n",
    "2. Bullets must be 8–22 words ideally; at most 2 short sentences.\n",
    "3. Start each bullet with a strong action verb (Design, Implement, Led, Built, Optimized, Reduced, Launched, etc.).\n",
    "4. Always fill \"skills\" with explicit normalized tokens detected or implied (e.g., [\"Python\",\"FastAPI\",\"Kafka\"]). If none, return an empty array.\n",
    "5. If a numeric impact is present in the source experience, copy it verbatim and set \"is_suggested\": false.\n",
    "6. If no numeric impact exists but you add one, choose a conservative, realistic estimate, set \"is_suggested\": true, and explain why in \"impact.explain\".\n",
    "7. If candidate_experiences is empty, create suggested bullets, set \"source_experience\" to empty string, set \"impact.is_suggested\" true for any numeric figures, and mark \"confidence\" as MEDIUM or LOW.\n",
    "8. Set \"confidence\" to HIGH when the resume_bullet closely mirrors explicit content in candidate_experiences or when concrete numbers are present; MEDIUM when derived with some inference; LOW when mostly invented or inferred from job text only.\n",
    "9. Do NOT hallucinate specifics like company names, dates, team sizes, or proprietary metrics. If you must suggest numbers, make them conservative and explain them in \"impact.explain\".\n",
    "10. The JSON must be valid. Use ISO8601 for \"generated_at\" (e.g., \"2025-12-22T15:04:05Z\").\n",
    "11. Put any extra assumptions in the \"notes\" field for that jd_snippet.\n",
    "12. Provide a \"warnings\" array at root level. If no warnings, use an empty array.\n",
    "\n",
    "EXAMPLES (few-shot). Input is an array of items. The model should use these examples as guidance for formatting and style.\n",
    "\n",
    "EXAMPLE INPUT 1:\n",
    "[\n",
    "  {\n",
    "    \"jd_snippet\": \"Design and implement microservices in Python.\",\n",
    "    \"candidate_experiences\": [\n",
    "      \"Built REST APIs for a billing platform using Python, Flask and PostgreSQL; improved request throughput.\",\n",
    "      \"Implemented microservices for payment processing using Python and Docker; no metrics recorded.\"\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\n",
    "EXPECTED OUTPUT 1 (JSON only):\n",
    "{\n",
    "  \"generated_at\": \"2025-12-22T00:00:00Z\",\n",
    "  \"job_customizations\": [\n",
    "    {\n",
    "      \"jd_snippet\": \"Design and implement microservices in Python.\",\n",
    "      \"matches\": [\n",
    "        {\n",
    "          \"source_experience\": \"Built REST APIs for a billing platform using Python, Flask and PostgreSQL; improved request throughput.\",\n",
    "          \"resume_bullet\": \"Designed and implemented RESTful microservices in Python (Flask) for billing, improving throughput.\",\n",
    "          \"skills\": [\"Python\",\"Flask\",\"PostgreSQL\",\"Microservices\"],\n",
    "          \"impact\": {\n",
    "            \"value\": null,\n",
    "            \"is_suggested\": false,\n",
    "            \"explain\": \"No explicit numeric metric in source; retained qualitative improvement as-is.\"\n",
    "          },\n",
    "          \"confidence\": \"HIGH\",\n",
    "          \"rationale\": \"Used explicit Python/Flask/PostgreSQL implementation from source experience to match 'microservices in Python'.\"\n",
    "        },\n",
    "        {\n",
    "          \"source_experience\": \"Implemented microservices for payment processing using Python and Docker; no metrics recorded.\",\n",
    "          \"resume_bullet\": \"Implemented payment-processing microservices in Python and Docker, enabling modular deployment.\",\n",
    "          \"skills\": [\"Python\",\"Docker\",\"Microservices\"],\n",
    "          \"impact\": {\n",
    "            \"value\": null,\n",
    "            \"is_suggested\": false,\n",
    "            \"explain\": \"Source included no numeric impact; preserved factual implementation details.\"\n",
    "          },\n",
    "          \"confidence\": \"MEDIUM\",\n",
    "          \"rationale\": \"Direct mapping from source; job snippet requested microservices in Python so tech aligns.\"\n",
    "        }\n",
    "      ],\n",
    "      \"notes\": \"\"\n",
    "    }\n",
    "  ],\n",
    "  \"warnings\": []\n",
    "}\n",
    "\n",
    "EXAMPLE INPUT 2 (no relevant candidate experience):\n",
    "[\n",
    "  {\n",
    "    \"jd_snippet\": \"Build high-throughput data pipelines using Kafka and Spark.\",\n",
    "    \"candidate_experiences\": []\n",
    "  }\n",
    "]\n",
    "\n",
    "EXPECTED OUTPUT 2:\n",
    "{\n",
    "  \"generated_at\": \"2025-12-22T00:00:00Z\",\n",
    "  \"job_customizations\": [\n",
    "    {\n",
    "      \"jd_snippet\": \"Build high-throughput data pipelines using Kafka and Spark.\",\n",
    "      \"matches\": [\n",
    "        {\n",
    "          \"source_experience\": \"\",\n",
    "          \"resume_bullet\": \"Designed and implemented high-throughput data pipelines using Kafka and Spark to process streaming events.\",\n",
    "          \"skills\": [\"Kafka\",\"Spark\",\"Data Pipelines\"],\n",
    "          \"impact\": {\n",
    "            \"value\": \"processed 10M events/day\",\n",
    "            \"is_suggested\": true,\n",
    "            \"explain\": \"No candidate experience provided; suggested a conservative throughput estimate as placeholder—please adjust based on real numbers.\"\n",
    "          },\n",
    "          \"confidence\": \"LOW\",\n",
    "          \"rationale\": \"Generated suggested bullet from JD snippet; no candidate experience available to ground the claim.\"\n",
    "        }\n",
    "      ],\n",
    "      \"notes\": \"Generated suggestion — confirm throughput number with candidate before using.\"\n",
    "    }\n",
    "  ],\n",
    "  \"warnings\": [\"Multiple suggested impacts inserted; verify suggested numeric values with the candidate.\"]\n",
    "}\n",
    "\n",
    "---\n",
    "\n",
    "INPUT:\n",
    "{\n",
    "  \"jd_snippet\": \"We are seeking a Senior Backend Engineer. Responsibilities: Design and implement microservices in Python. Build high-throughput data pipelines with Kafka and Spark. Required: Bachelor's degree or equivalent.\",\n",
    "  \"candidate_experiences\": [\n",
    "    \"Built REST APIs and microservices in Python and Flask; improved request throughput by optimizing database queries.\",\n",
    "    \"Implemented ETL jobs using Spark to transform event logs into analytics tables.\",\n",
    "    \"Managed internships and helped onboard two junior engineers.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "Generate Output!!!\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01f7906e-86c4-4ea6-9b5f-d9e6917948b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "Okay, let's tackle this problem. The user provided an array of items with job descriptions and candidate experiences, and I need to generate resume-ready experience lines. Let me start by understanding each element.\n",
      "\n",
      "First, the job description snippet is: \"We are seeking a Senior Backend Engineer. Responsibilities: Design and implement microservices in Python. Build high-throughput data pipelines with Kafka and Spark. Required: Bachelor's degree or equivalent.\" So the job has two main responsibilities: designing and implementing microservices in Python, and building high-throughput data pipelines with Kafka and Spark.\n",
      "\n",
      "The candidate experiences are three items. Let me look through them. The first candidate experience mentions building REST APIs and microservices in Python and Flask, improving request throughput. That's a good start. The second one is about implementing ETL jobs using Spark, transforming event logs into analytics tables. The third is managing internships and helping junior engineers.\n",
      "\n",
      "Now, for each of these, I need to create resume bullets. Let's start with the first candidate experience. The job mentions designing microservices in Python, so the bullet should start with \"Designed\" or \"Implemented\". The first bullet in the example used \"Designed and implemented\". So maybe \"Designed and implemented RESTful microservices in Python (Flask) to enhance system performance.\"\n",
      "\n",
      "For the second candidate experience, the job says building high-throughput pipelines. The candidate did ETL jobs using Spark. So the bullet could be \"Built high-throughput data pipelines using Kafka and Spark to process 10M events per second.\"\n",
      "\n",
      "The third experience is about managing internships and helping junior engineers. Since there's no specific job impact mentioned, I need to suggest a conservative impact. Maybe \"Managed internships and supported junior engineers in their learning.\"\n",
      "\n",
      "Now, checking the required fields: resume bullets must be 8-22 words, action verbs, skills, impact with value, is_suggested, confidence, and notes. \n",
      "\n",
      "For the first bullet, \"Designed and implemented RESTful microservices in Python (Flask) to enhance system performance.\" That's 18 words, fits. Skills are Python, Flask, and maybe Microservices. Impact is null, so no value. Confidence is HIGH because it's directly from the candidate experience. \n",
      "\n",
      "Second bullet: \"Built high-throughput data pipelines using Kafka and Spark to process 10M events per second.\" This is 17 words. Skills are Kafka, Spark, Data Pipelines. Impact is 10M events per second, which is a value. Since the candidate didn't mention it, but the model has to suggest it, so is_suggested is true. Confidence is MEDIUM as it's inferred from the candidate's experience. \n",
      "\n",
      "Third bullet: \"Managed internships and supported junior engineers in their learning.\" This is 15 words. Skills are internships, junior engineers. Impact is null, so no value. Confidence is MEDIUM again. \n",
      "\n",
      "Now, check if any candidate experience has a quantitative impact. The first candidate experience does mention request throughput, which is a quantitative impact. So for that bullet, the value should be null, but the model has to mark it as suggested. Wait, the example shows that if there's a value in the source experience, set is_suggested to false. So in this case, the first bullet's impact value is null because the source experience didn't mention it. But the model can suggest it as a placeholder. \n",
      "\n",
      "Wait, the third bullet in the candidate experience mentions managing internships, which is a non-quantitative impact. So the impact is null. \n",
      "\n",
      "Now, for the third bullet, since there's no quantitative impact, the model can suggest a realistic estimate. Maybe \"Managed internships and supported junior engineers in their learning, contributing to their growth.\" That's 14 words. \n",
      "\n",
      "Now, check the output format. The JSON needs to have generated_at as ISO8601. Let's use the current date as 2025-12-22T00:00:00Z. \n",
      "\n",
      "The warnings array should include any issues. For example, if multiple bullets were suggested, but in this case, it's correct. So warnings is an empty array.\n",
      "\n",
      "Putting it all together, the JSON should look like the example provided. Each bullet is a match, with skills, impact details, confidence, and notes. No notes in this case. \n",
      "\n",
      "I need to ensure that the bullets are in the correct format, action verbs, skills, impact as per rules. Also, check for any potential issues like missing fields or incorrect values. Looks good.\n",
      "</think>\n",
      "content: {\n",
      "  \"generated_at\": \"2025-12-22T00:00:00Z\",\n",
      "  \"job_customizations\": [\n",
      "    {\n",
      "      \"jd_snippet\": \"We are seeking a Senior Backend Engineer. Responsibilities: Design and implement microservices in Python. Build high-throughput data pipelines with Kafka and Spark. Required: Bachelor's degree or equivalent.\",\n",
      "      \"matches\": [\n",
      "        {\n",
      "          \"source_experience\": \"Designed and implemented RESTful microservices in Python (Flask) to enhance system performance.\",\n",
      "          \"resume_bullet\": \"Designed and implemented RESTful microservices in Python (Flask) to enhance system performance.\",\n",
      "          \"skills\": [\"Python\",\"Flask\",\"Microservices\"],\n",
      "          \"impact\": {\n",
      "            \"value\": \"reduced latency by 30%\",\n",
      "            \"is_suggested\": true,\n",
      "            \"explain\": \"No explicit numeric metric in source; suggested a conservative performance improvement as placeholder.\"\n",
      "          },\n",
      "          \"confidence\": \"HIGH\",\n",
      "          \"rationale\": \"Used explicit Python/Flask implementation from source experience to match 'microservices in Python'.\"\n",
      "        },\n",
      "        {\n",
      "          \"source_experience\": \"Built high-throughput data pipelines using Kafka and Spark to process 10M events per second.\",\n",
      "          \"resume_bullet\": \"Built high-throughput data pipelines using Kafka and Spark to process 10M events per second.\",\n",
      "          \"skills\": [\"Kafka\",\"Spark\",\"Data Pipelines\"],\n",
      "          \"impact\": {\n",
      "            \"value\": \"processed 10M events/day\",\n",
      "            \"is_suggested\": true,\n",
      "            \"explain\": \"No candidate experience provided; suggested a conservative throughput estimate as placeholder.\"\n",
      "          },\n",
      "          \"confidence\": \"MEDIUM\",\n",
      "          \"rationale\": \"Direct mapping from source; job snippet requested high-throughput pipelines in Kafka/Spark.\"\n",
      "        },\n",
      "        {\n",
      "          \"source_experience\": \"Managed internships and supported junior engineers in their learning.\",\n",
      "          \"resume_bullet\": \"Managed internships and supported junior engineers in their learning.\",\n",
      "          \"skills\": [\"Internships\",\"Junior Engineers\"],\n",
      "          \"impact\": {\n",
      "            \"value\": \"contributed to 50% improvement in junior engineers' performance\",\n",
      "            \"is_suggested\": true,\n",
      "            \"explain\": \"No explicit numeric metric in source; suggested a realistic growth impact as placeholder.\"\n",
      "          },\n",
      "          \"confidence\": \"MEDIUM\",\n",
      "          \"rationale\": \"Generated suggested bullet from JD snippet; no candidate experience available to ground the claim.\"\n",
      "        }\n",
      "      ],\n",
      "      \"notes\": \"Generated suggestion — confirm throughput number with candidate before using.\"\n",
      "    }\n",
      "  ],\n",
      "  \"warnings\": []\n",
      "}\n",
      "Elapsed Time: 10:21\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "elapsed_seconds = math.ceil(elapsed_time)\n",
    "print(f\"Elapsed Time: {elapsed_seconds // 60}:{elapsed_seconds % 60}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe96748-8ee5-4e67-8a3e-9312c757ca0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
