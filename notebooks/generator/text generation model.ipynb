{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3421ceea-03bd-47bb-8588-9ed8a25f7fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50916a0e-e296-4dcb-8a00-05f6042f4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fb46f31-9d8c-4d74-97f0-0b68ea6f888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.get_default_device()\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d139ca32-6803-429a-ae10-19f99953dea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5bb5f67ede439ca35a0e60255fa725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76517dbf526b457184714faea4ea18b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "# load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "596ade78-b128-4bbd-a767-d7195f3f7949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thinking content: <think>\n",
      "Okay, let's start by looking at the user's job description and their relevant experience. The user wants the experience rewritten to fit the job description and to suggest quantitative measures for polishing the experience. \n",
      "\n",
      "First, I need to compare the job description with the experience. The user mentioned that the experience is not well-suited, so I should identify what areas need improvement. For example, if the job requires data analysis skills, the experience should highlight relevant skills and projects.\n",
      "\n",
      "Next, I should check for any gaps. Maybe the user didn't mention specific projects or achievements that align with the job requirements. Quantitative measures can help add value by showing measurable results. For instance, if the job involves project management, they could mention tasks completed, time spent, or metrics achieved.\n",
      "\n",
      "I need to make sure the rewritten experience is concise and highlights the key points. Also, adding quantitative metrics will make the experience more impressive and show that the user is capable of delivering results. It's important to tailor the suggestions to the specific job and experience to maximize relevance.\n",
      "\n",
      "Wait, the user also mentioned that they want to suggest quantitative measures. So, I should think about which areas of experience could be quantified. For example, if the experience includes developing a solution, maybe they could mention the number of features developed, time spent, or cost savings.\n",
      "\n",
      "I should also check if the user has any specific job titles or roles in mind. Sometimes, the job description might have certain requirements that the experience doesn't meet. For example, if the job is remote, the experience should mention remote work or collaboration metrics.\n",
      "\n",
      "Finally, I need to present the rewritten experience clearly and suggest the quantitative measures. Making sure the advice is actionable and tailored to the job description to improve the user's application.\n",
      "</think>\n",
      "content: Here’s a revised experience tailored to your job description, followed by suggestions for quantitative measures to enhance your application:\n",
      "\n",
      "---\n",
      "\n",
      "### **Revised Experience**\n",
      "\n",
      "**Job Title:** [Insert Job Title]  \n",
      "**Company:** [Insert Company Name]  \n",
      "**Location:** [Insert Location]\n",
      "\n",
      "As a [Your Role], I successfully [briefly describe your role, e.g., \"developed a scalable solution for [specific project/department]\"] by [specific action, e.g., \"streamlined operations by [specific metric]\"]. This experience aligns with the [job description key points, e.g., \"data-driven decision-making\", \"project management\"] and supports the [job objective, e.g., \"enhance productivity and client satisfaction\"].\n",
      "\n",
      "**Key Achievements:**\n",
      "- [Quantify a measurable result, e.g., \"achieved a 20% reduction in processing time for [specific task]\"]\n",
      "- [Quantify another achievement, e.g., \"developed X features with a budget of $[number]\"]\n",
      "- [Quantify a collaboration metric, e.g., \"managed 5+ cross-functional teams with a task completion rate of 95%\"]\n",
      "\n",
      "---\n",
      "\n",
      "### **Suggested Quantitative Measures for Polishing**\n",
      "\n",
      "1. **Project Management Metrics**  \n",
      "   - Time Spent on Projects: [Insert number]  \n",
      "   - Task Completion Rate: [Insert percentage]  \n",
      "   - Cost Savings: [Insert dollar value]  \n",
      "\n",
      "2. **Technical Skills**  \n",
      "   - Number of Relevant Skills Earned: [Insert number]  \n",
      "   - Time Spent Learning New Technologies: [Insert number]  \n",
      "\n",
      "3. **Collaboration and Communication**  \n",
      "   - Number of Cross-Functional Team Members: [Insert number]  \n",
      "   - Project Deadlines Met: [Insert percentage]  \n",
      "\n",
      "4. **Problem-Solving Results**  \n",
      "   - Number of Unique Solutions Implemented: [Insert number]  \n",
      "   - Time to Resolve Critical Issues: [Insert number]  \n",
      "\n",
      "5. **Budget/ROI Metrics**  \n",
      "   - Cost of Projects: [Insert number]  \n",
      "   - Return on Investment: [Insert percentage]  \n",
      "\n",
      "---\n",
      "\n",
      "### **Why This Matters**\n",
      "Adding these quantitative measures strengthens your application by demonstrating your capability to deliver measurable results, align with the job’s requirements, and showcase your skills in a data-driven way. Tailoring the experience to the job’s specific objectives will maximize your application’s impact.\n",
      "Elapsed Time: 4:7\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "# prepare the model input\n",
    "prompt = \"I will give some job description and my relevant experience. Will you rewrite the experience so that it well suited to the job description. Also, you need to suggest if some quantitative measures can be added to more polish the experience.\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    "    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "# conduct text completion\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=32768\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist() \n",
    "\n",
    "# parsing thinking content\n",
    "try:\n",
    "    # rindex finding 151668 (</think>)\n",
    "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
    "except ValueError:\n",
    "    index = 0\n",
    "\n",
    "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
    "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
    "\n",
    "print(\"thinking content:\", thinking_content)\n",
    "print(\"content:\", content)\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "elapsed_seconds = math.ceil(elapsed_time)\n",
    "print(f\"Elapsed Time: {elapsed_seconds // 60}:{elapsed_seconds % 60}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
